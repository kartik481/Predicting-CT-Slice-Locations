{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478d6f71",
   "metadata": {},
   "source": [
    "## Prediction of the relative location of CT slices on axial axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d2315",
   "metadata": {},
   "source": [
    "### Support code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15209180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_support_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276432ca",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07121aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data\n",
    "data = np.load('ct_data.npz')\n",
    "\n",
    "## X's\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "\n",
    "## y's\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a3dea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of y_train: -9.13868774539957e-15\n",
      "Mean of y_train (for 5785 entries): -0.44247687859693674\n",
      "Standard error for y_train (for 5785 entries): 0.011927303389170828\n",
      "Mean of y_val (for 5785 entries): -0.2160085093241599\n",
      "Standard error for y_val (for 5785 entries): 0.01290449880016868\n"
     ]
    }
   ],
   "source": [
    "## calculating requested means and std errors on those means \n",
    "\n",
    "## training data\n",
    "\n",
    "print(\"Mean of y_train:\",np.mean(y_train))\n",
    "print(\"Mean of y_train (for 5785 entries):\", np.mean(y_train[:5785]))\n",
    "print(\"Standard error for y_train (for 5785 entries):\",np.std(y_train[:5785], ddof=1)/np.sqrt(len(y_train[:5785])))\n",
    "\n",
    "## validation data\n",
    "\n",
    "print(\"Mean of y_val (for 5785 entries):\",np.mean(y_val))\n",
    "print(\"Standard error for y_val (for 5785 entries):\",np.std(y_val, ddof=1)/np.sqrt(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831bdc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed constant columns (as in the original array) indices are: [59, 69, 179, 189, 351]\n",
      "Removed duplicate column (as in the original array) indices are: [354, 195, 76, 77, 185, 283]\n"
     ]
    }
   ],
   "source": [
    "## removing constant and duplicate features\n",
    "\n",
    "## constants\n",
    "\n",
    "rm_idx0=[]    \n",
    "\n",
    "for i in range(len(X_train[1])):\n",
    "    col=X_train[:,i]\n",
    "    if all(col[0]==col):\n",
    "        rm_idx0.append(i)\n",
    "print(\"Removed constant columns (as in the original array) indices are:\", rm_idx0) \n",
    "\n",
    "\n",
    "X_train = np.delete(X_train,rm_idx0,axis=1)\n",
    "X_val = np.delete(X_val, rm_idx0, axis=1)\n",
    "X_test = np.delete(X_test, rm_idx0, axis=1)\n",
    "\n",
    "\n",
    "## duplicates\n",
    "\n",
    "indices= np.unique(X_train,return_index=True,axis=1)[1]\n",
    "\n",
    "indices=np.sort(indices)\n",
    "rm_idx=list(set(range(indices[0],indices[-1]+1))-set(indices))\n",
    "\n",
    "X_train = np.delete(X_train,rm_idx,axis=1)\n",
    "X_val = np.delete(X_val, rm_idx, axis=1)\n",
    "X_test = np.delete(X_test, rm_idx, axis=1)\n",
    "\n",
    "print(\"Removed duplicate column (as in the original array) indices are:\",rm_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c72a9",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef57ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linreg(X, yy, alpha):\n",
    "    k=len(X[1])                                 ## getting number of input features\n",
    "    yy = np.concatenate((yy, np.zeros(k)))      ## adding 0_k to the y_train array\n",
    "    z_k = np.sqrt(alpha) * np.eye(k)\n",
    "    X = np.vstack((X,z_k))  \n",
    "    \n",
    "    b = np.concatenate((np.ones(len(X)-k), np.zeros(k)))[:,None]\n",
    "\n",
    "    X = np.insert(X,[0],b,axis=1)\n",
    "\n",
    "    w_fit=np.linalg.lstsq(X, yy, rcond=None)[0]\n",
    "    \n",
    "    \n",
    "    return w_fit[1:], w_fit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee88f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=30\n",
    "\n",
    "## least squares weights & bias\n",
    "ww0, bb0 = fit_linreg(X_train, y_train, alpha)\n",
    "\n",
    "## gradient method weights & bias\n",
    "ww1,bb1 = fit_linreg_gradopt(X_train, y_train, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324e48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining rmse\n",
    "\n",
    "def rmse(pred,yy):\n",
    "    return np.sqrt(np.mean((pred-yy)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6a178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training set (using least squares method): 0.3567565397204054\n",
      "RMSE for validation set (using least squares method): 0.42305219683946976\n"
     ]
    }
   ],
   "source": [
    "## for least squares method\n",
    "\n",
    "pred1_train = np.dot(X_train,ww0)+bb0\n",
    "pred1_val = np.dot(X_val,ww0)+bb0\n",
    "print(\"RMSE for training set (using least squares method):\",rmse(pred1_train, y_train))\n",
    "print(\"RMSE for validation set (using least squares method):\",rmse(pred1_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9778bf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training set (using gradient method): 0.35675597702036305\n",
      "RMSE for validation set (using gradient method): 0.4230550153899789\n"
     ]
    }
   ],
   "source": [
    "## for gradient method\n",
    "\n",
    "pred2_train = np.dot(X_train,ww1)+bb1\n",
    "pred2_val = np.dot(X_val,ww1)+bb1\n",
    "print(\"RMSE for training set (using gradient method):\",rmse(pred2_train, y_train))\n",
    "print(\"RMSE for validation set (using gradient method):\",rmse(pred2_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4caa973",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8504d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## modified function\n",
    "\n",
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    \"\"\"\n",
    "    fit a regularized linear regression model with gradient opt\n",
    "\n",
    "         ww, bb = fit_linreg_gradopt(X, yy, alpha)\n",
    "\n",
    "     Find weights and bias by using a gradient-based optimizer\n",
    "     (minimize_list) to improve the regularized least squares cost:\n",
    "\n",
    "       np.sum(((np.dot(X,ww) + bb) - yy)**2) + alpha*np.dot(ww,ww)\n",
    "\n",
    "     Inputs:\n",
    "             X N,D design matrix of input features\n",
    "            yy N,  real-valued targets\n",
    "         alpha     scalar regularization constant\n",
    "\n",
    "     Outputs:\n",
    "            ww D,  fitted weights\n",
    "            bb     scalar fitted bias\n",
    "    \"\"\"\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "\n",
    "\n",
    "K = 20 # number of thresholded classification problems to fit\n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "\n",
    "w_fit2= np.array([[0.0]* (len(X_train[1])+1)] * K)\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    ww2, bb2 = fit_logreg_gradopt(X_train, labels, alpha=30)\n",
    "    w_fit2[kk,0] = bb2\n",
    "    w_fit2[kk,1:]=ww2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8257b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2_hat = w_fit2[:,0]\n",
    "ww2_hat = w_fit2[:,1:]\n",
    "\n",
    "## defining sigmoid\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1 / (1+np.exp(-a))\n",
    "\n",
    "\n",
    "\n",
    "X_train_new = sigmoid(np.dot(X_train, np.transpose(ww2_hat))+bb2_hat) \n",
    "X_val_new = sigmoid(np.dot(X_val, np.transpose(ww2_hat))+bb2_hat)\n",
    "\n",
    "\n",
    "nn_ww, nn_bb = fit_linreg(X_train_new, y_train, alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de6e79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training set: 0.1544115042984819\n",
      "RMSE for validation set: 0.2542477297888156\n"
     ]
    }
   ],
   "source": [
    "pred3_train = np.dot(X_train_new, nn_ww) + nn_bb\n",
    "pred3_val = np.dot(X_val_new, nn_ww) + nn_bb\n",
    "\n",
    "print(\"RMSE for training set:\",rmse(pred3_train, y_train))\n",
    "print(\"RMSE for validation set:\",rmse(pred3_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a99e5",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf7eb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) ## for random weight initialization\n",
    "\n",
    "\n",
    "def fit_nn_gradopt(X, yy, K, alpha, w_random = True):\n",
    "    \"\"\"\n",
    "    fit a regularized linear regression model with gradient opt\n",
    "\n",
    "         ww, bb = fit_linreg_gradopt(X, yy, alpha)\n",
    "\n",
    "     Find weights and bias by using a gradient-based optimizer\n",
    "     (minimize_list) to improve the regularized least squares cost:\n",
    "\n",
    "       np.sum(((np.dot(X,ww) + bb) - yy)**2) + alpha*np.dot(ww,ww)\n",
    "\n",
    "     Inputs:\n",
    "             X N,D design matrix of input features\n",
    "            yy N,  real-valued targets\n",
    "         alpha     scalar regularization constant\n",
    "         w_random  controls random initialisation of weights\n",
    "\n",
    "     Outputs:\n",
    "            ww D,  fitted weights\n",
    "            bb     scalar fitted bias\n",
    "    \"\"\"\n",
    "    args = (X, yy, alpha)\n",
    "    \n",
    "    if w_random:\n",
    "        \n",
    "        D = len(X_train[1])\n",
    "       \n",
    "    \n",
    "        # generate random initialisation\n",
    "        ww = 0.1 * np.random.randn(K)/np.sqrt(K)\n",
    "        V = 0.1 * np.random.randn(K,D)/np.sqrt(D)\n",
    "        bk = np.zeros(K)\n",
    "        bb= 0\n",
    "        init = (ww, bb, V, bk)\n",
    "        ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "        return (ww, bb, V, bk)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        init = (nn_ww,nn_bb,ww2_hat, bb2_hat)            ## Initialization from the results we obtained \n",
    "        ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "        return (ww, bb, V, bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9e02c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fit_nn_gradopt(X_train, y_train,K=20, alpha=30)\n",
    "\n",
    "pred_train_nn= nn_cost(params, X_train, yy=None, alpha=30)\n",
    "pred_val_nn= nn_cost(params, X_val, yy=None, alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1290c841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE for NN (with random initialization): 0.14023263982522416\n",
      "Validation set RMSE for NN (with random initialization): 0.27047491191944456\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set RMSE for NN (with random initialization):\",rmse(pred_train_nn, y_train))\n",
    "print(\"Validation set RMSE for NN (with random initialization):\",rmse(pred_val_nn, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = fit_nn_gradopt(X_train, y_train,K=20, alpha=30, w_random = False)\n",
    "\n",
    "pred1_train_nn= nn_cost(params2, X_train, yy=None, alpha=30)\n",
    "pred1_val_nn= nn_cost(params2, X_val, yy=None, alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fdb4062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE for NN (with initialization from q3): 0.13963009839601498\n",
      "Validation set RMSE for NN (with initialization from q3): 0.26857721499074866\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set RMSE for NN (with initialization from q3):\",rmse(pred1_train_nn, y_train))\n",
    "print(\"Validation set RMSE for NN (with initialization from q3):\",rmse(pred1_val_nn, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23611ebb",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5293197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_reg(X_train, X_val, yy, y_val, train_alpha):\n",
    "    \n",
    "    param = fit_nn_gradopt(X_train, yy, K=20, alpha= train_alpha)\n",
    "    \n",
    "    pred_val = nn_cost(param, X_val, yy=None, alpha= train_alpha)\n",
    "\n",
    "    return (rmse(pred_val,y_val), param)\n",
    "    \n",
    "    \n",
    "alpha= np.arange(0,50,0.02)\n",
    "\n",
    "indicies = np.random.choice(len(alpha),3) \n",
    "obs_alpha = np.array(alpha[indicies])\n",
    "test_alpha = np.delete(alpha,indicies)\n",
    "\n",
    "obs_alpha_val = np.array([])\n",
    "\n",
    "for alpha in obs_alpha: \n",
    "    val_rmse = train_nn_reg(X_train, X_val, y_train, y_val, alpha)[0]\n",
    "    obs_alpha_val = np.append(obs_alpha_val, val_rmse )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b287d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of improvement for Alpha(=0.0) is 0.5827825928435952 and Validation RMSE is: 0.27360064710085197\n",
      "Probability of improvement for Alpha(=11.200000000000001) is 0.5406420072971778 and Validation RMSE is: 0.2520158993589383\n",
      "Probability of improvement for Alpha(=11.58) is 0.37340378241418304 and Validation RMSE is: 0.25856636671937655\n",
      "Probability of improvement for Alpha(=8.82) is 0.32007921055127664 and Validation RMSE is: 0.25322312424903504\n",
      "Probability of improvement for Alpha(=8.84) is 0.34952151149666943 and Validation RMSE is: 0.26230654140428356\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "log_base_rmse = np.log(rmse(pred_val_nn, y_val))    ## Validation rmse from question 4a\n",
    "\n",
    "y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "\n",
    "post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    " \n",
    "post_std = np.sqrt(np.diag(post_cov))         ## Standard deviation\n",
    "\n",
    "def phi(post_mean, post_std, y):\n",
    "    return scipy.stats.norm.cdf((post_mean - max(y))/post_std)\n",
    "\n",
    "best_alpha = 0.0\n",
    "best_alpha_rmse = 9999.0\n",
    "best_params = set()\n",
    "for _ in range(5):\n",
    "    prob_max = phi(post_mean, post_std, y)\n",
    "    idx = np.argmax(prob_max)\n",
    "    \n",
    "    \n",
    "    alpha_val_rmse, params = train_nn_reg(X_train, X_val, y_train, y_val, test_alpha[idx])\n",
    "    \n",
    "    if  alpha_val_rmse < best_alpha_rmse:\n",
    "        best_alpha = test_alpha[idx]\n",
    "        best_alpha_rmse = alpha_val_rmse\n",
    "        best_params = params\n",
    "    \n",
    "    print(\"Probability of improvement for Alpha(={0}) is {1} and Validation RMSE is: {2}\".format( \n",
    "                                test_alpha[idx], prob_max[idx], alpha_val_rmse))\n",
    "    \n",
    "    obs_alpha_val = np.append(obs_alpha_val, alpha_val_rmse)\n",
    "    \n",
    "    obs_alpha = np.append(obs_alpha, test_alpha[idx])\n",
    "    test_alpha = np.delete(test_alpha,idx)\n",
    "\n",
    "    y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "    post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    "    post_std = np.sqrt(np.diag(post_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5df959f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best value for alpha is 11.200000000000001\n",
      "The Validation error is 0.2520158993589383\n",
      "The Test error is 0.27222277241918336\n"
     ]
    }
   ],
   "source": [
    "## Traning on best alpha to get test error\n",
    "pred_test = nn_cost(best_params, X_test, yy=None, alpha=best_alpha)   ## Prediction for test set\n",
    "test_error = rmse(pred_test, y_test)\n",
    "\n",
    "print(\"The Best value for alpha is {0}\".format(best_alpha))\n",
    "print(\"The Validation error is {0}\".format(best_alpha_rmse))\n",
    "print(\"The Test error is {0}\".format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9073e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2589297557830086"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn_reg(X_train, X_val, y_train, y_val, best_alpha)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05aed668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2626651816225229"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn_reg(X_train, X_val, y_train, y_val, best_alpha)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e73bab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we modify train_nn_reg to take K as an input \n",
    "def mod_train_nn_reg(X_train, X_val, yy, y_val, train_alpha, KK):\n",
    "    \n",
    "    param = fit_nn_gradopt(X_train, yy, K=KK, alpha= train_alpha)\n",
    "    \n",
    "    pred_val = nn_cost(param, X_val, yy=None, alpha= train_alpha)\n",
    "\n",
    "    return (rmse(pred_val,y_val), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8819a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden units 10\n",
      "Best alpha 5.78\n",
      "Validation set RMSE 0.2599445630445513\n",
      "Number of hidden units 15\n",
      "Best alpha 7.74\n",
      "Validation set RMSE 0.24618513988232724\n",
      "Number of hidden units 20\n",
      "Best alpha 5.16\n",
      "Validation set RMSE 0.24505883414892754\n",
      "Number of hidden units 25\n",
      "Best alpha 3.14\n",
      "Validation set RMSE 0.24128592977064098\n",
      "Number of hidden units 30\n",
      "Best alpha 0.0\n",
      "Validation set RMSE 0.24403786646251396\n",
      "Number of hidden units 35\n",
      "Best alpha 10.26\n",
      "Validation set RMSE 0.25321938582862785\n",
      "Number of hidden units 40\n",
      "Best alpha 2.2600000000000002\n",
      "Validation set RMSE 0.24460565428212663\n",
      "Number of hidden units 45\n",
      "Best alpha 1.6400000000000001\n",
      "Validation set RMSE 0.2469754066843032\n",
      "Number of hidden units 50\n",
      "Best alpha 2.42\n",
      "Validation set RMSE 0.23386218646544207\n",
      "Number of hidden units 55\n",
      "Best alpha 3.12\n",
      "Validation set RMSE 0.2404677049863256\n"
     ]
    }
   ],
   "source": [
    "## vector of different hidden neurons to try \n",
    "\n",
    "KK = np.array([10,15,20,25,30,35,40,45,50,55])\n",
    "\n",
    "## we iteratively apply what we did in q5 \n",
    "\n",
    "for kk in KK:\n",
    "    \n",
    "    alpha= np.arange(0,50,0.02)\n",
    "\n",
    "    indicies = np.random.choice(len(alpha),3) \n",
    "    obs_alpha = np.array(alpha[indicies])\n",
    "    test_alpha = np.delete(alpha,indicies)\n",
    "\n",
    "    obs_alpha_val = np.array([])\n",
    "\n",
    "    for alpha in obs_alpha: \n",
    "        val_rmse = mod_train_nn_reg(X_train, X_val, y_train, y_val, alpha,kk)[0]\n",
    "        obs_alpha_val = np.append(obs_alpha_val, val_rmse )\n",
    "    \n",
    "    y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "    post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    "    post_std = np.sqrt(np.diag(post_cov))         ## Standard deviation\n",
    "    best_alpha = 0.0\n",
    "    best_alpha_rmse = 9999.0\n",
    "    best_params = set()\n",
    "    \n",
    "    for _ in range(5):\n",
    "        prob_max = phi(post_mean, post_std, y)\n",
    "        idx = np.argmax(prob_max)\n",
    "    \n",
    "    \n",
    "        alpha_val_rmse, params = mod_train_nn_reg(X_train, X_val, y_train, y_val, test_alpha[idx],kk)\n",
    "    \n",
    "        if  alpha_val_rmse < best_alpha_rmse:\n",
    "            best_alpha = test_alpha[idx]\n",
    "            best_alpha_rmse = alpha_val_rmse\n",
    "            best_params = params\n",
    "    \n",
    "        obs_alpha_val = np.append(obs_alpha_val, alpha_val_rmse)\n",
    "    \n",
    "        obs_alpha = np.append(obs_alpha, test_alpha[idx])\n",
    "        test_alpha = np.delete(test_alpha,idx)\n",
    "\n",
    "        y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "        post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    "        post_std = np.sqrt(np.diag(post_cov))\n",
    "        \n",
    "    print(\"Number of hidden units {0}\".format(kk))\n",
    "    print(\"Best alpha {0}\".format(best_alpha))\n",
    "    print(\"Validation set RMSE {0}\".format(best_alpha_rmse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fda0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params = mod_train_nn_reg(X_train, X_val, y_train, y_val, 2.42,50)[1]\n",
    "pred_best_test = nn_cost(best_model_params, X_test, yy=None, alpha=best_alpha)   ## Prediction for test set\n",
    "test_error = rmse(pred_best_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6474523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28878344490785907\n"
     ]
    }
   ],
   "source": [
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ae947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

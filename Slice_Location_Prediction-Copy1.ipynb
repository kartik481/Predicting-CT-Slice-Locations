{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478d6f71",
   "metadata": {},
   "source": [
    "## Prediction of the relative location of CT slices on axial axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d2315",
   "metadata": {},
   "source": [
    "### Support code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15209180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_support_code import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c0075",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c744e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data\n",
    "data = np.load('ct_data.npz')\n",
    "\n",
    "## X's\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "\n",
    "## y's\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37188c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of y_train: -9.13868774539957e-15\n",
      "Mean of y_train (for 5785 entries): -0.44247687859693674\n",
      "Standard error for y_train (for 5785 entries): 0.011927303389170828\n",
      "Mean of y_val (for 5785 entries): -0.2160085093241599\n",
      "Standard error for y_val (for 5785 entries): 0.01290449880016868\n"
     ]
    }
   ],
   "source": [
    "## calculating requested means and std errors on those means \n",
    "\n",
    "## training data\n",
    "\n",
    "print(\"Mean of y_train:\",np.mean(y_train))\n",
    "print(\"Mean of y_train (for 5785 entries):\", np.mean(y_train[:5785]))\n",
    "print(\"Standard error for y_train (for 5785 entries):\",np.std(y_train[:5785], ddof=1)/np.sqrt(len(y_train[:5785])))\n",
    "\n",
    "## validation data\n",
    "\n",
    "print(\"Mean of y_val (for 5785 entries):\",np.mean(y_val))\n",
    "print(\"Standard error for y_val (for 5785 entries):\",np.std(y_val, ddof=1)/np.sqrt(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f84cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed constant columns (as in the original array) indices are: [59, 69, 179, 189, 351]\n",
      "Removed duplicate column (as in the original array) indices are: [354, 195, 76, 77, 185, 283]\n"
     ]
    }
   ],
   "source": [
    "## removing constant and duplicate features\n",
    "\n",
    "## constants\n",
    "\n",
    "rm_idx0=[]    \n",
    "\n",
    "for i in range(len(X_train[1])):\n",
    "    col=X_train[:,i]\n",
    "    if all(col[0]==col):\n",
    "        rm_idx0.append(i)\n",
    "print(\"Removed constant columns (as in the original array) indices are:\", rm_idx0) \n",
    "\n",
    "\n",
    "X_train = np.delete(X_train,rm_idx0,axis=1)\n",
    "X_val = np.delete(X_val, rm_idx0, axis=1)\n",
    "X_test = np.delete(X_test, rm_idx0, axis=1)\n",
    "\n",
    "\n",
    "## duplicates\n",
    "\n",
    "indices= np.unique(X_train,return_index=True,axis=1)[1]\n",
    "\n",
    "indices=np.sort(indices)\n",
    "rm_idx=list(set(range(indices[0],indices[-1]+1))-set(indices))\n",
    "\n",
    "X_train = np.delete(X_train,rm_idx,axis=1)\n",
    "X_val = np.delete(X_val, rm_idx, axis=1)\n",
    "X_test = np.delete(X_test, rm_idx, axis=1)\n",
    "\n",
    "print(\"Removed duplicate column (as in the original array) indices are:\",rm_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b7447",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f12d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linreg(X, yy, alpha):\n",
    "    k=len(X[1])                                 ## getting number of input features\n",
    "    yy = np.concatenate((yy, np.zeros(k)))      ## adding 0_k to the y_train array\n",
    "    z_k = np.sqrt(alpha) * np.eye(k)\n",
    "    X = np.vstack((X,z_k))  \n",
    "    \n",
    "    b = np.concatenate((np.ones(len(X)-k), np.zeros(k)))[:,None]\n",
    "\n",
    "    X = np.insert(X,[0],b,axis=1)\n",
    "\n",
    "    w_fit=np.linalg.lstsq(X, yy, rcond=None)[0]\n",
    "    \n",
    "    \n",
    "    return w_fit[1:], w_fit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5851f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=30\n",
    "\n",
    "## least squares weights & bias\n",
    "ww0, bb0 = fit_linreg(X_train, y_train, alpha)\n",
    "\n",
    "## gradient method weights & bias\n",
    "ww1,bb1 = fit_linreg_gradopt(X_train, y_train, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbdaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining rmse\n",
    "\n",
    "def rmse(pred,yy):\n",
    "    return np.sqrt(np.mean((pred-yy)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c525d01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training set (using least squares method): 0.3567565397204054\n",
      "RMSE for validation set (using least squares method): 0.42305219683946976\n"
     ]
    }
   ],
   "source": [
    "## for least squares method\n",
    "\n",
    "pred1_train = np.dot(X_train,ww0)+bb0\n",
    "pred1_val = np.dot(X_val,ww0)+bb0\n",
    "print(\"RMSE for training set (using least squares method):\",rmse(pred1_train, y_train))\n",
    "print(\"RMSE for validation set (using least squares method):\",rmse(pred1_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6457af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training set (using gradient method): 0.35675597702036305\n",
      "RMSE for validation set (using gradient method): 0.4230550153899789\n"
     ]
    }
   ],
   "source": [
    "## for gradient method\n",
    "\n",
    "pred2_train = np.dot(X_train,ww1)+bb1\n",
    "pred2_val = np.dot(X_val,ww1)+bb1\n",
    "print(\"RMSE for training set (using gradient method):\",rmse(pred2_train, y_train))\n",
    "print(\"RMSE for validation set (using gradient method):\",rmse(pred2_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0839cf5c",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d766fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## modified function\n",
    "\n",
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    \"\"\"\n",
    "    fit a regularized linear regression model with gradient opt\n",
    "\n",
    "         ww, bb = fit_linreg_gradopt(X, yy, alpha)\n",
    "\n",
    "     Find weights and bias by using a gradient-based optimizer\n",
    "     (minimize_list) to improve the regularized least squares cost:\n",
    "\n",
    "       np.sum(((np.dot(X,ww) + bb) - yy)**2) + alpha*np.dot(ww,ww)\n",
    "\n",
    "     Inputs:\n",
    "             X N,D design matrix of input features\n",
    "            yy N,  real-valued targets\n",
    "         alpha     scalar regularization constant\n",
    "\n",
    "     Outputs:\n",
    "            ww D,  fitted weights\n",
    "            bb     scalar fitted bias\n",
    "    \"\"\"\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "\n",
    "\n",
    "K = 20 # number of thresholded classification problems to fit\n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "\n",
    "w_fit2= np.array([[0.0]* (len(X_train[1])+1)] * K)\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    ww2, bb2 = fit_logreg_gradopt(X_train, labels, alpha=30)\n",
    "    w_fit2[kk,0] = bb2\n",
    "    w_fit2[kk,1:]=ww2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec84f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2_hat = w_fit2[:,0]\n",
    "ww2_hat = w_fit2[:,1:]\n",
    "\n",
    "## defining sigmoid\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1 / (1+np.exp(-a))\n",
    "\n",
    "\n",
    "\n",
    "X_train_new = sigmoid(np.dot(X_train, np.transpose(ww2_hat))+bb2_hat) \n",
    "X_val_new = sigmoid(np.dot(X_val, np.transpose(ww2_hat))+bb2_hat)\n",
    "\n",
    "\n",
    "nn_ww, nn_bb = fit_linreg(X_train_new, y_train, alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a242d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training set: 0.1544115042984819\n",
      "RMSE for validation set: 0.2542477297888156\n"
     ]
    }
   ],
   "source": [
    "pred3_train = np.dot(X_train_new, nn_ww) + nn_bb\n",
    "pred3_val = np.dot(X_val_new, nn_ww) + nn_bb\n",
    "\n",
    "print(\"RMSE for training set:\",rmse(pred3_train, y_train))\n",
    "print(\"RMSE for validation set:\",rmse(pred3_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f3c38",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd8f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) ## for random weight initialization\n",
    "\n",
    "\n",
    "def fit_nn_gradopt(X, yy, K, alpha, w_random = True):\n",
    "    \"\"\"\n",
    "    fit a regularized linear regression model with gradient opt\n",
    "\n",
    "         ww, bb = fit_linreg_gradopt(X, yy, alpha)\n",
    "\n",
    "     Find weights and bias by using a gradient-based optimizer\n",
    "     (minimize_list) to improve the regularized least squares cost:\n",
    "\n",
    "       np.sum(((np.dot(X,ww) + bb) - yy)**2) + alpha*np.dot(ww,ww)\n",
    "\n",
    "     Inputs:\n",
    "             X N,D design matrix of input features\n",
    "            yy N,  real-valued targets\n",
    "         alpha     scalar regularization constant\n",
    "         w_random  controls random initialisation of weights\n",
    "\n",
    "     Outputs:\n",
    "            ww D,  fitted weights\n",
    "            bb     scalar fitted bias\n",
    "    \"\"\"\n",
    "    args = (X, yy, alpha)\n",
    "    \n",
    "    if w_random:\n",
    "        \n",
    "        D = len(X_train[1])\n",
    "       \n",
    "    \n",
    "        # generate random initialisation\n",
    "        ww = 0.1 * np.random.randn(K)/np.sqrt(K)\n",
    "        V = 0.1 * np.random.randn(K,D)/np.sqrt(D)\n",
    "        bk = np.zeros(K)\n",
    "        bb= 0\n",
    "        init = (ww, bb, V, bk)\n",
    "        ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "        return (ww, bb, V, bk)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        init = (nn_ww,nn_bb,ww2_hat, bb2_hat)            ## Initialization from the results we obtained \n",
    "        ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "        return (ww, bb, V, bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b33267e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fit_nn_gradopt(X_train, y_train,K=20, alpha=30)\n",
    "\n",
    "pred_train_nn= nn_cost(params, X_train, yy=None, alpha=30)\n",
    "pred_val_nn= nn_cost(params, X_val, yy=None, alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "288b9a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE for NN (with random initialization): 0.14023263982522416\n",
      "Validation set RMSE for NN (with random initialization): 0.27047491191944456\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set RMSE for NN (with random initialization):\",rmse(pred_train_nn, y_train))\n",
    "print(\"Validation set RMSE for NN (with random initialization):\",rmse(pred_val_nn, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f6e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = fit_nn_gradopt(X_train, y_train,K=20, alpha=30, w_random = False)\n",
    "\n",
    "pred1_train_nn= nn_cost(params2, X_train, yy=None, alpha=30)\n",
    "pred1_val_nn= nn_cost(params2, X_val, yy=None, alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948610fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE for NN (with initialization from q3): 0.13963009839601498\n",
      "Validation set RMSE for NN (with initialization from q3): 0.26857721499074866\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set RMSE for NN (with initialization from q3):\",rmse(pred1_train_nn, y_train))\n",
    "print(\"Validation set RMSE for NN (with initialization from q3):\",rmse(pred1_val_nn, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59e65c",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fa4cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_reg(X_train, X_val, yy, y_val, train_alpha):\n",
    "    \n",
    "    param = fit_nn_gradopt(X_train, yy, K=20, alpha= train_alpha)\n",
    "    \n",
    "    pred_val = nn_cost(param, X_val, yy=None, alpha= train_alpha)\n",
    "\n",
    "    return (rmse(pred_val,y_val), param)\n",
    "    \n",
    "    \n",
    "alpha= np.arange(0,50,0.02)\n",
    "\n",
    "indicies = np.random.choice(len(alpha),3) \n",
    "obs_alpha = np.array(alpha[indicies])\n",
    "test_alpha = np.delete(alpha,indicies)\n",
    "\n",
    "obs_alpha_val = np.array([])\n",
    "\n",
    "for alpha in obs_alpha: \n",
    "    val_rmse = train_nn_reg(X_train, X_val, y_train, y_val, alpha)[0]\n",
    "    obs_alpha_val = np.append(obs_alpha_val, val_rmse )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779492b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of improvement for Alpha(=0.0) is 0.5827825928435952 and Validation RMSE is: 0.27360064710085197\n",
      "Probability of improvement for Alpha(=11.200000000000001) is 0.5406420072971778 and Validation RMSE is: 0.2520158993589383\n",
      "Probability of improvement for Alpha(=11.58) is 0.37340378241418304 and Validation RMSE is: 0.25856636671937655\n",
      "Probability of improvement for Alpha(=8.82) is 0.32007921055127664 and Validation RMSE is: 0.25322312424903504\n",
      "Probability of improvement for Alpha(=8.84) is 0.34952151149666943 and Validation RMSE is: 0.26230654140428356\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "log_base_rmse = np.log(rmse(pred_val_nn, y_val))    ## Validation rmse from question 4a\n",
    "\n",
    "y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "\n",
    "post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    " \n",
    "post_std = np.sqrt(np.diag(post_cov))         ## Standard deviation\n",
    "\n",
    "def phi(post_mean, post_std, y):\n",
    "    return scipy.stats.norm.cdf((post_mean - max(y))/post_std)\n",
    "\n",
    "best_alpha = 0.0\n",
    "best_alpha_rmse = 9999.0\n",
    "best_params = set()\n",
    "for _ in range(5):\n",
    "    prob_max = phi(post_mean, post_std, y)\n",
    "    idx = np.argmax(prob_max)\n",
    "    \n",
    "    \n",
    "    alpha_val_rmse, params = train_nn_reg(X_train, X_val, y_train, y_val, test_alpha[idx])\n",
    "    \n",
    "    if  alpha_val_rmse < best_alpha_rmse:\n",
    "        best_alpha = test_alpha[idx]\n",
    "        best_alpha_rmse = alpha_val_rmse\n",
    "        best_params = params\n",
    "    \n",
    "    print(\"Probability of improvement for Alpha(={0}) is {1} and Validation RMSE is: {2}\".format( \n",
    "                                test_alpha[idx], prob_max[idx], alpha_val_rmse))\n",
    "    \n",
    "    obs_alpha_val = np.append(obs_alpha_val, alpha_val_rmse)\n",
    "    \n",
    "    obs_alpha = np.append(obs_alpha, test_alpha[idx])\n",
    "    test_alpha = np.delete(test_alpha,idx)\n",
    "\n",
    "    y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "    post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    "    post_std = np.sqrt(np.diag(post_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7576f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best value for alpha is 11.200000000000001\n",
      "The Validation error is 0.2520158993589383\n",
      "The Test error is 0.27222277241918336\n"
     ]
    }
   ],
   "source": [
    "## Traning on best alpha to get test error\n",
    "pred_test = nn_cost(best_params, X_test, yy=None, alpha=best_alpha)   ## Prediction for test set\n",
    "test_error = rmse(pred_test, y_test)\n",
    "\n",
    "print(\"The Best value for alpha is {0}\".format(best_alpha))\n",
    "print(\"The Validation error is {0}\".format(best_alpha_rmse))\n",
    "print(\"The Test error is {0}\".format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a595bd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2589297557830086"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn_reg(X_train, X_val, y_train, y_val, best_alpha)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee1c133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2626651816225229"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn_reg(X_train, X_val, y_train, y_val, best_alpha)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc8e5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_train_nn_reg(X_train, X_val, yy, y_val, train_alpha, KK):\n",
    "    \n",
    "    param = fit_nn_gradopt(X_train, yy, K=KK, alpha= train_alpha)\n",
    "    \n",
    "    pred_val = nn_cost(param, X_val, yy=None, alpha= train_alpha)\n",
    "\n",
    "    return (rmse(pred_val,y_val), param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fedfc5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden units10\n",
      "Best alpha14.36\n",
      "Validation set RMSE0.258420627930365\n",
      "Number of hidden units10\n",
      "Best alpha14.36\n",
      "Validation set RMSE0.258420627930365\n",
      "Number of hidden units10\n",
      "Best alpha14.36\n",
      "Validation set RMSE0.258420627930365\n",
      "Number of hidden units10\n",
      "Best alpha14.36\n",
      "Validation set RMSE0.258420627930365\n",
      "Number of hidden units10\n",
      "Best alpha14.36\n",
      "Validation set RMSE0.258420627930365\n",
      "Number of hidden units20\n",
      "Best alpha32.160000000000004\n",
      "Validation set RMSE0.27748351430027884\n",
      "Number of hidden units20\n",
      "Best alpha0.0\n",
      "Validation set RMSE0.260600482202473\n",
      "Number of hidden units20\n",
      "Best alpha0.02\n",
      "Validation set RMSE0.2540269207381081\n",
      "Number of hidden units20\n",
      "Best alpha3.2\n",
      "Validation set RMSE0.22684314477771944\n",
      "Number of hidden units20\n",
      "Best alpha3.2\n",
      "Validation set RMSE0.22684314477771944\n",
      "Number of hidden units30\n",
      "Best alpha4.6000000000000005\n",
      "Validation set RMSE0.24898237963583714\n",
      "Number of hidden units30\n",
      "Best alpha4.6000000000000005\n",
      "Validation set RMSE0.24898237963583714\n",
      "Number of hidden units30\n",
      "Best alpha0.0\n",
      "Validation set RMSE0.24493226905436694\n",
      "Number of hidden units30\n",
      "Best alpha0.0\n",
      "Validation set RMSE0.24493226905436694\n",
      "Number of hidden units30\n",
      "Best alpha0.0\n",
      "Validation set RMSE0.24493226905436694\n",
      "Number of hidden units40\n",
      "Best alpha1.76\n",
      "Validation set RMSE0.25677691291611193\n",
      "Number of hidden units40\n",
      "Best alpha4.8\n",
      "Validation set RMSE0.2561163339141154\n",
      "Number of hidden units40\n",
      "Best alpha4.8\n",
      "Validation set RMSE0.2561163339141154\n",
      "Number of hidden units40\n",
      "Best alpha4.8\n",
      "Validation set RMSE0.2561163339141154\n",
      "Number of hidden units40\n",
      "Best alpha4.8\n",
      "Validation set RMSE0.2561163339141154\n",
      "Number of hidden units50\n",
      "Best alpha3.2800000000000002\n",
      "Validation set RMSE0.24474955075521596\n",
      "Number of hidden units50\n",
      "Best alpha3.2800000000000002\n",
      "Validation set RMSE0.24474955075521596\n",
      "Number of hidden units50\n",
      "Best alpha3.2800000000000002\n",
      "Validation set RMSE0.24474955075521596\n",
      "Number of hidden units50\n",
      "Best alpha3.2800000000000002\n",
      "Validation set RMSE0.24474955075521596\n",
      "Number of hidden units50\n",
      "Best alpha3.2800000000000002\n",
      "Validation set RMSE0.24474955075521596\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m obs_alpha_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m obs_alpha: \n\u001b[1;32m---> 18\u001b[0m     val_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmod_train_nn_reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkk\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m     obs_alpha_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(obs_alpha_val, val_rmse )\n\u001b[0;32m     21\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(log_base_rmse \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(obs_alpha_val))\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mmod_train_nn_reg\u001b[1;34m(X_train, X_val, yy, y_val, train_alpha, KK)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmod_train_nn_reg\u001b[39m(X_train, X_val, yy, y_val, train_alpha,KK):\n\u001b[1;32m----> 3\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mfit_nn_gradopt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_alpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     pred_val \u001b[38;5;241m=\u001b[39m nn_cost(param, X_val, yy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m train_alpha)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (rmse(pred_val,y_val), param)\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mfit_nn_gradopt\u001b[1;34m(X, yy, K, alpha, w_random)\u001b[0m\n\u001b[0;32m     36\u001b[0m     bb\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     37\u001b[0m     init \u001b[38;5;241m=\u001b[39m (ww, bb, V, bk)\n\u001b[1;32m---> 38\u001b[0m     ww, bb, V, bk \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ww, bb, V, bk)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\MLPR22_23\\ct_support_code.py:58\u001b[0m, in \u001b[0;36mminimize_list\u001b[1;34m(cost, init_list, args)\u001b[0m\n\u001b[0;32m     56\u001b[0m     vec_bar, _ \u001b[38;5;241m=\u001b[39m params_wrap(params_bar)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m E, vec_bar\n\u001b[1;32m---> 58\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrap_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unwrap(res\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    624\u001b[0m                             callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    354\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mC:\\PythonProg\\lib\\site-packages\\scipy\\optimize\\optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 68\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\MLPR22_23\\ct_support_code.py:55\u001b[0m, in \u001b[0;36mminimize_list.<locals>.wrap_cost\u001b[1;34m(vec, *args)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_cost\u001b[39m(vec, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m---> 55\u001b[0m     E, params_bar \u001b[38;5;241m=\u001b[39m \u001b[43mcost\u001b[49m\u001b[43m(\u001b[49m\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     vec_bar, _ \u001b[38;5;241m=\u001b[39m params_wrap(params_bar)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m E, vec_bar\n",
      "File \u001b[1;32m~\\MLPR22_23\\ct_support_code.py:196\u001b[0m, in \u001b[0;36mnn_cost\u001b[1;34m(params, X, yy, alpha)\u001b[0m\n\u001b[0;32m    194\u001b[0m bb_bar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(F_bar) \u001b[38;5;66;03m# scalar\u001b[39;00m\n\u001b[0;32m    195\u001b[0m P_bar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(F_bar[:,\u001b[38;5;28;01mNone\u001b[39;00m], ww[\u001b[38;5;28;01mNone\u001b[39;00m,:]) \u001b[38;5;66;03m# N,K\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m A_bar \u001b[38;5;241m=\u001b[39m \u001b[43mP_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m P) \u001b[38;5;66;03m# N,K\u001b[39;00m\n\u001b[0;32m    197\u001b[0m V_bar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A_bar\u001b[38;5;241m.\u001b[39mT, X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39malpha\u001b[38;5;241m*\u001b[39mV \u001b[38;5;66;03m# K,D\u001b[39;00m\n\u001b[0;32m    198\u001b[0m bk_bar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(A_bar, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## vector of different hidden neurons to try \n",
    "\n",
    "KK = np.array([10,20,30,40,50,60,70,80])\n",
    "\n",
    "## we iteratively apply what we did in q5 \n",
    "\n",
    "for kk in KK:\n",
    "    \n",
    "    alpha= np.arange(0,50,0.02)\n",
    "\n",
    "    indicies = np.random.choice(len(alpha),3) \n",
    "    obs_alpha = np.array(alpha[indicies])\n",
    "    test_alpha = np.delete(alpha,indicies)\n",
    "\n",
    "    obs_alpha_val = np.array([])\n",
    "\n",
    "    for alpha in obs_alpha: \n",
    "        val_rmse = mod_train_nn_reg(X_train, X_val, y_train, y_val, alpha,kk)[0]\n",
    "        obs_alpha_val = np.append(obs_alpha_val, val_rmse )\n",
    "    \n",
    "    y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "    post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    "    post_std = np.sqrt(np.diag(post_cov))         ## Standard deviation\n",
    "    best_alpha = 0.0\n",
    "    best_alpha_rmse = 9999.0\n",
    "    best_params = set()\n",
    "    for _ in range(5):\n",
    "        prob_max = phi(post_mean, post_std, y)\n",
    "        idx = np.argmax(prob_max)\n",
    "    \n",
    "    \n",
    "        alpha_val_rmse, params = mod_train_nn_reg(X_train, X_val, y_train, y_val, test_alpha[idx],kk)\n",
    "    \n",
    "        if  alpha_val_rmse < best_alpha_rmse:\n",
    "            best_alpha = test_alpha[idx]\n",
    "            best_alpha_rmse = alpha_val_rmse\n",
    "            best_params = params\n",
    "    \n",
    "        obs_alpha_val = np.append(obs_alpha_val, alpha_val_rmse)\n",
    "    \n",
    "        obs_alpha = np.append(obs_alpha, test_alpha[idx])\n",
    "        test_alpha = np.delete(test_alpha,idx)\n",
    "\n",
    "        y = np.array(log_base_rmse - np.log(obs_alpha_val))\n",
    "        post_mean, post_cov  = gp_post_par(test_alpha, obs_alpha, y)\n",
    "        post_std = np.sqrt(np.diag(post_cov))\n",
    "        \n",
    "    print(\"Number of hidden units{0}\".format(kk))\n",
    "    print(\"Best alpha{0}\".format(best_alpha))\n",
    "    print(\"Validation set RMSE{0}\".format(best_alpha_rmse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f01b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
